2017-11-28 10:32:19.412956: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:892] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-11-28 10:32:19.413195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1031] Found device 0 with properties: 
name: GeForce GTX 1080 Ti major: 6 minor: 1 memoryClockRate(GHz): 1.582
pciBusID: 0000:01:00.0
totalMemory: 10.91GiB freeMemory: 10.75GiB
2017-11-28 10:32:19.413208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] Creating TensorFlow device (/device:GPU:0) -> (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1)
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
dense_1 (Dense)              (None, 1024)              1684480   
_________________________________________________________________
adaptative_bi_hyperbolic_1 ( (None, 1024)              3072      
_________________________________________________________________
dropout_1 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_2 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
adaptative_bi_hyperbolic_2 ( (None, 1024)              3072      
_________________________________________________________________
dropout_2 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_3 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
adaptative_bi_hyperbolic_3 ( (None, 1024)              3072      
_________________________________________________________________
dropout_3 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_4 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
adaptative_bi_hyperbolic_4 ( (None, 1024)              3072      
_________________________________________________________________
dropout_4 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_5 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
adaptative_bi_hyperbolic_5 ( (None, 1024)              3072      
_________________________________________________________________
dropout_5 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_6 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
adaptative_bi_hyperbolic_6 ( (None, 1024)              3072      
_________________________________________________________________
dropout_6 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_7 (Dense)              (None, 1024)              1049600   
_________________________________________________________________
adaptative_bi_hyperbolic_7 ( (None, 1024)              3072      
_________________________________________________________________
dropout_7 (Dropout)          (None, 1024)              0         
_________________________________________________________________
dense_8 (Dense)              (None, 2)                 2050      
_________________________________________________________________
activation_1 (Activation)    (None, 2)                 0         
=================================================================
Total params: 8,005,634
Trainable params: 8,005,634
Non-trainable params: 0
_________________________________________________________________
Train on 7596 samples, validate on 845 samples
Epoch 1/100
 128/7596 [..............................] - ETA: 84s - loss: 8.2444 - acc: 0.35941024/7596 [===>..........................] - ETA: 9s - loss: nan - acc: 0.8076    1792/7596 [======>.......................] - ETA: 5s - loss: nan - acc: 0.83712560/7596 [=========>....................] - ETA: 3s - loss: nan - acc: 0.84843328/7596 [============>.................] - ETA: 2s - loss: nan - acc: 0.85884096/7596 [===============>..............] - ETA: 1s - loss: nan - acc: 0.86234864/7596 [==================>...........] - ETA: 0s - loss: nan - acc: 0.86125632/7596 [=====================>........] - ETA: 0s - loss: nan - acc: 0.85926400/7596 [========================>.....] - ETA: 0s - loss: nan - acc: 0.86097168/7596 [===========================>..] - ETA: 0s - loss: nan - acc: 0.86647596/7596 [==============================] - 2s - loss: nan - acc: 0.8669 - val_loss: nan - val_acc: 0.9515
Epoch 2/100
 128/7596 [..............................] - ETA: 0s - loss: nan - acc: 0.86721024/7596 [===>..........................] - ETA: 0s - loss: nan - acc: 0.88871920/7596 [======>.......................] - ETA: 0s - loss: nan - acc: 0.89222816/7596 [==========>...................] - ETA: 0s - loss: nan - acc: 0.88173712/7596 [=============>................] - ETA: 0s - loss: nan - acc: 0.88074608/7596 [=================>............] - ETA: 0s - loss: nan - acc: 0.87985504/7596 [====================>.........] - ETA: 0s - loss: nan - acc: 0.87636272/7596 [=======================>......] - ETA: 0s - loss: nan - acc: 0.87587168/7596 [===========================>..] - ETA: 0s - loss: nan - acc: 0.87777596/7596 [==============================] - 0s - loss: nan - acc: 0.8763 - val_loss: nan - val_acc: 0.9515
Epoch 3/100
 128/7596 [..............................] - ETA: 0s - loss: nan - acc: 0.86721024/7596 [===>..........................] - ETA: 0s - loss: nan - acc: 0.87211792/7596 [======>.......................] - ETA: 0s - loss: nan - acc: 0.86102560/7596 [=========>....................] - ETA: 0s - loss: nan - acc: 0.86763328/7596 [============>.................] - ETA: 0s - loss: nan - acc: 0.87114096/7596 [===============>..............] - ETA: 0s - loss: nan - acc: 0.87164864/7596 [==================>...........] - ETA: 0s - loss: nan - acc: 0.87445632/7596 [=====================>........] - ETA: 0s - loss: nan - acc: 0.87506400/7596 [========================>.....] - ETA: 0s - loss: nan - acc: 0.87707040/7596 [==========================>...] - ETA: 0s - loss: nan - acc: 0.87677596/7596 [==============================] - 0s - loss: nan - acc: 0.8763 - val_loss: nan - val_acc: 0.9515
Epoch 4/100
 128/7596 [..............................] - ETA: 0s - loss: nan - acc: 0.9219 768/7596 [==>...........................] - ETA: 0s - loss: nan - acc: 0.87371408/7596 [====>.........................] - ETA: 0s - loss: nan - acc: 0.87712048/7596 [=======>......................] - ETA: 0s - loss: nan - acc: 0.87792688/7596 [=========>....................] - ETA: 0s - loss: nan - acc: 0.87503328/7596 [============>.................] - ETA: 0s - loss: nan - acc: 0.87593968/7596 [==============>...............] - ETA: 0s - loss: nan - acc: 0.87534608/7596 [=================>............] - ETA: 0s - loss: nan - acc: 0.87575248/7596 [===================>..........] - ETA: 0s - loss: nan - acc: 0.87395888/7596 [======================>.......] - ETA: 0s - loss: nan - acc: 0.87486528/7596 [========================>.....] - ETA: 0s - loss: nan - acc: 0.87657296/7596 [===========================>..] - ETA: 0s - loss: nan - acc: 0.87757596/7596 [==============================] - 0s - loss: nan - acc: 0.8763 - val_loss: nan - val_acc: 0.9515
Epoch 5/100
 128/7596 [..............................] - ETA: 0s - loss: nan - acc: 0.8828 896/7596 [==>...........................] - ETA: 0s - loss: nan - acc: 0.88061664/7596 [=====>........................] - ETA: 0s - loss: nan - acc: 0.87322560/7596 [=========>....................] - ETA: 0s - loss: nan - acc: 0.87153456/7596 [============>.................] - ETA: 0s - loss: nan - acc: 0.87504352/7596 [================>.............] - ETA: 0s - loss: nan - acc: 0.87485248/7596 [===================>..........] - ETA: 0s - loss: nan - acc: 0.87486016/7596 [======================>.......] - ETA: 0s - loss: nan - acc: 0.87526912/7596 [==========================>...] - ETA: 0s - loss: nan - acc: 0.87637596/7596 [==============================] - 0s - loss: nan - acc: 0.8763 - val_loss: nan - val_acc: 0.9515
Epoch 6/100
 128/7596 [..............................] - ETA: 0s - loss: nan - acc: 0.84381024/7596 [===>..........................] - ETA: 0s - loss: nan - acc: 0.86231920/7596 [======>.......................] - ETA: 0s - loss: nan - acc: 0.87342816/7596 [==========>...................] - ETA: 0s - loss: nan - acc: 0.86793712/7596 [=============>................] - ETA: 0s - loss: nan - acc: 0.87374608/7596 [=================>............] - ETA: 0s - loss: nan - acc: 0.87615504/7596 [====================>.........] - ETA: 0s - loss: nan - acc: 0.87556400/7596 [========================>.....] - ETA: 0s - loss: nan - acc: 0.87587296/7596 [===========================>..] - ETA: 0s - loss: nan - acc: 0.87477596/7596 [==============================] - 0s - loss: nan - acc: 0.8763 - val_loss: nan - val_acc: 0.9515
 32/610 [>.............................] - ETA: 1sUsing TensorFlow backend.
Traceback (most recent call last):
  File "tox21.py", line 97, in <module>
    auc_te = roc_auc_score(y_te[target][rows_te], p_te[:, 1])
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py", line 265, in roc_auc_score
    sample_weight=sample_weight)
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/base.py", line 75, in _average_binary_score
    return binary_metric(y_true, y_score, sample_weight=sample_weight)
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py", line 260, in _binary_roc_auc_score
    sample_weight=sample_weight)
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py", line 510, in roc_curve
    y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/metrics/ranking.py", line 306, in _binary_clf_curve
    assert_all_finite(y_score)
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py", line 53, in assert_all_finite
    _assert_all_finite(X.data if sp.issparse(X) else X)
  File "/home/canalli/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py", line 43, in _assert_all_finite
    " or a value too large for %r." % X.dtype)
ValueError: Input contains NaN, infinity or a value too large for dtype('float32').
